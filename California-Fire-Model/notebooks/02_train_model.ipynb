{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üî• California Fire Model - Training Notebook\n",
                "\n",
                "This notebook trains a burn severity detection model on California wildfire data.\n",
                "\n",
                "## Prerequisites\n",
                "1. Run `data/download_fire_data.py` to queue data downloads\n",
                "2. Download data from Google Drive to `data/raw/`\n",
                "3. Run `data/compute_statistics.py` to calculate normalization stats\n",
                "4. Run `data/validate_dataset.py` to check data quality"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Only run this cell in Google Colab\n",
                "# Uncomment if needed:\n",
                "\n",
                "# from google.colab import drive\n",
                "# drive.mount('/content/drive')\n",
                "\n",
                "# # Copy data to local SSD for faster training\n",
                "# !mkdir -p /content/local_data\n",
                "# !cp -r /content/drive/MyDrive/California_Fire_Model/* /content/local_data/"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "from pathlib import Path\n",
                "\n",
                "# Add project to path\n",
                "PROJECT_ROOT = Path('.').resolve()\n",
                "sys.path.insert(0, str(PROJECT_ROOT))\n",
                "\n",
                "# Imports\n",
                "import torch\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "from config import (\n",
                "    TRAINING_CONFIG, MODEL_CONFIG, CHECKPOINT_DIR, RAW_DATA_DIR,\n",
                "    TRAINING_FIRES, TEST_FIRES, print_config_summary\n",
                ")\n",
                "\n",
                "# Print configuration\n",
                "print_config_summary()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup Device"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"\\nüîß Device: {device}\")\n",
                "\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
                "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Create Datasets"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from data.dataset import create_train_val_datasets\n",
                "from torch.utils.data import DataLoader\n",
                "\n",
                "# Data directories\n",
                "data_dirs = [\n",
                "    str(RAW_DATA_DIR / \"fires\"),\n",
                "    str(RAW_DATA_DIR / \"healthy\"),\n",
                "]\n",
                "\n",
                "# Check data exists\n",
                "for d in data_dirs:\n",
                "    exists = Path(d).exists()\n",
                "    count = len(list(Path(d).glob('**/*.tif'))) if exists else 0\n",
                "    status = '‚úÖ' if count > 0 else '‚ùå'\n",
                "    print(f\"{status} {d}: {count} tiles\")\n",
                "\n",
                "# Create datasets\n",
                "train_dataset, val_dataset, test_dataset = create_train_val_datasets(\n",
                "    data_dirs,\n",
                "    val_split=0.15,\n",
                ")\n",
                "\n",
                "print(f\"\\nüìä Dataset sizes:\")\n",
                "print(f\"   Train: {len(train_dataset)}\")\n",
                "print(f\"   Val: {len(val_dataset)}\")\n",
                "print(f\"   Test: {len(test_dataset)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create dataloaders\n",
                "batch_size = TRAINING_CONFIG['batch_size']\n",
                "\n",
                "train_loader = DataLoader(\n",
                "    train_dataset,\n",
                "    batch_size=batch_size,\n",
                "    shuffle=True,\n",
                "    num_workers=TRAINING_CONFIG['num_workers'],\n",
                "    pin_memory=True,\n",
                "    drop_last=True,\n",
                ")\n",
                "\n",
                "val_loader = DataLoader(\n",
                "    val_dataset,\n",
                "    batch_size=batch_size,\n",
                "    shuffle=False,\n",
                "    num_workers=TRAINING_CONFIG['num_workers'],\n",
                "    pin_memory=True,\n",
                ")\n",
                "\n",
                "print(f\"\\nüì¶ DataLoaders:\")\n",
                "print(f\"   Train batches: {len(train_loader)}\")\n",
                "print(f\"   Val batches: {len(val_loader)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Visualize Sample Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from inference.visualize import rgb_from_sentinel2, get_severity_cmap\n",
                "\n",
                "# Get a sample batch\n",
                "images, labels = next(iter(train_loader))\n",
                "print(f\"Batch shapes: images={images.shape}, labels={labels.shape}\")\n",
                "\n",
                "# Visualize first 4 samples\n",
                "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
                "\n",
                "cmap = get_severity_cmap()\n",
                "\n",
                "for i in range(4):\n",
                "    # RGB (denormalize roughly)\n",
                "    img = images[i].numpy()\n",
                "    img = img * 6 - 3  # Undo [0,1] normalization\n",
                "    img = img * np.array([545, 476, 571, 532, 614, 731, 811, 872, 856, 611]).reshape(-1, 1, 1)\n",
                "    img = img + np.array([1339, 1167, 1002, 1296, 1835, 2149, 2290, 2410, 2004, 1075]).reshape(-1, 1, 1)\n",
                "    rgb = rgb_from_sentinel2(img)\n",
                "    \n",
                "    axes[0, i].imshow(rgb)\n",
                "    axes[0, i].set_title(f\"RGB {i+1}\")\n",
                "    axes[0, i].axis('off')\n",
                "    \n",
                "    # Label\n",
                "    label = labels[i, 0].numpy()\n",
                "    im = axes[1, i].imshow(label, cmap=cmap, vmin=0, vmax=1)\n",
                "    axes[1, i].set_title(f\"Severity (mean: {label.mean():.1%})\")\n",
                "    axes[1, i].axis('off')\n",
                "    \n",
                "plt.colorbar(im, ax=axes[1, :].tolist(), shrink=0.6)\n",
                "plt.suptitle('Training Samples', fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Create Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from model.architecture import CaliforniaFireModel\n",
                "from model.losses import CombinedLoss\n",
                "\n",
                "# Create model\n",
                "model = CaliforniaFireModel(**MODEL_CONFIG).to(device)\n",
                "\n",
                "# Count parameters\n",
                "params = sum(p.numel() for p in model.parameters()) / 1e6\n",
                "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad) / 1e6\n",
                "\n",
                "print(f\"\\nüß† Model:\")\n",
                "print(f\"   Total parameters: {params:.2f}M\")\n",
                "print(f\"   Trainable: {trainable:.2f}M\")\n",
                "\n",
                "# Test forward pass\n",
                "x = torch.randn(2, 10, 256, 256).to(device)\n",
                "with torch.no_grad():\n",
                "    y = model(x)\n",
                "print(f\"\\n   Input: {x.shape}\")\n",
                "print(f\"   Output: {y.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Loss function\n",
                "criterion = CombinedLoss(\n",
                "    bce_weight=0.5,\n",
                "    dice_weight=0.5,\n",
                "    pos_weight=2.0,  # Weight burned pixels more\n",
                ")\n",
                "\n",
                "# Test loss\n",
                "with torch.no_grad():\n",
                "    images_gpu = images[:2].to(device)\n",
                "    labels_gpu = labels[:2].to(device)\n",
                "    logits = model(images_gpu)\n",
                "    loss, components = criterion(logits, labels_gpu)\n",
                "    \n",
                "print(f\"\\nüìâ Loss components:\")\n",
                "for k, v in components.items():\n",
                "    print(f\"   {k}: {v:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Train"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from training.train import Trainer\n",
                "import torch.optim as optim\n",
                "\n",
                "# Optimizer\n",
                "optimizer = optim.AdamW(\n",
                "    model.parameters(),\n",
                "    lr=TRAINING_CONFIG['learning_rate'],\n",
                "    weight_decay=TRAINING_CONFIG['weight_decay'],\n",
                ")\n",
                "\n",
                "# Scheduler\n",
                "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
                "    optimizer,\n",
                "    mode='min',\n",
                "    factor=TRAINING_CONFIG['lr_scheduler_factor'],\n",
                "    patience=TRAINING_CONFIG['lr_scheduler_patience'],\n",
                "    min_lr=1e-7,\n",
                ")\n",
                "\n",
                "# Create trainer\n",
                "trainer = Trainer(\n",
                "    model=model,\n",
                "    train_loader=train_loader,\n",
                "    val_loader=val_loader,\n",
                "    criterion=criterion,\n",
                "    optimizer=optimizer,\n",
                "    scheduler=scheduler,\n",
                "    device=device,\n",
                "    config=TRAINING_CONFIG,\n",
                ")\n",
                "\n",
                "print(\"‚úÖ Trainer ready!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train!\n",
                "results = trainer.train(epochs=TRAINING_CONFIG['epochs'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Plot Training History"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "history = results['history']\n",
                "\n",
                "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
                "\n",
                "# Loss\n",
                "axes[0, 0].plot(history['train_loss'], label='Train')\n",
                "axes[0, 0].plot(history['val_loss'], label='Val')\n",
                "axes[0, 0].set_xlabel('Epoch')\n",
                "axes[0, 0].set_ylabel('Loss')\n",
                "axes[0, 0].set_title('Loss')\n",
                "axes[0, 0].legend()\n",
                "axes[0, 0].grid(True, alpha=0.3)\n",
                "\n",
                "# IoU\n",
                "axes[0, 1].plot(history['val_iou'], 'g-', label='IoU')\n",
                "axes[0, 1].set_xlabel('Epoch')\n",
                "axes[0, 1].set_ylabel('IoU')\n",
                "axes[0, 1].set_title(f'Validation IoU (Best: {max(history[\"val_iou\"]):.4f})')\n",
                "axes[0, 1].grid(True, alpha=0.3)\n",
                "\n",
                "# MAE\n",
                "axes[1, 0].plot(history['val_mae'], 'r-', label='MAE')\n",
                "axes[1, 0].set_xlabel('Epoch')\n",
                "axes[1, 0].set_ylabel('MAE')\n",
                "axes[1, 0].set_title(f'Validation MAE (Best: {min(history[\"val_mae\"]):.4f})')\n",
                "axes[1, 0].grid(True, alpha=0.3)\n",
                "\n",
                "# LR\n",
                "axes[1, 1].semilogy(history['lr'])\n",
                "axes[1, 1].set_xlabel('Epoch')\n",
                "axes[1, 1].set_ylabel('Learning Rate')\n",
                "axes[1, 1].set_title('Learning Rate Schedule')\n",
                "axes[1, 1].grid(True, alpha=0.3)\n",
                "\n",
                "plt.suptitle('Training History', fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.savefig(str(CHECKPOINT_DIR / 'training_history.png'), dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Evaluate on Test Set"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from model.architecture import load_model\n",
                "from model.metrics import MetricTracker\n",
                "\n",
                "# Load best model\n",
                "best_model_path = CHECKPOINT_DIR / 'best_model.pth'\n",
                "best_model = load_model(str(best_model_path), device=str(device), **MODEL_CONFIG)\n",
                "\n",
                "# Test loader\n",
                "test_loader = DataLoader(\n",
                "    test_dataset,\n",
                "    batch_size=batch_size,\n",
                "    shuffle=False,\n",
                "    num_workers=2,\n",
                ")\n",
                "\n",
                "# Evaluate\n",
                "tracker = MetricTracker(threshold=0.5)\n",
                "best_model.eval()\n",
                "\n",
                "with torch.no_grad():\n",
                "    for batch in test_loader:\n",
                "        images, labels, metadata = batch\n",
                "        images = images.to(device)\n",
                "        labels = labels.to(device)\n",
                "        \n",
                "        logits = best_model(images)\n",
                "        \n",
                "        for i in range(images.size(0)):\n",
                "            fire_key = metadata['fire_key'][i]\n",
                "            tracker.update(logits[i:i+1], labels[i:i+1], category=fire_key)\n",
                "\n",
                "# Print results\n",
                "tracker.print_summary(prefix=\"üß™ TEST SET: \")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize test predictions\n",
                "from inference.visualize import plot_prediction\n",
                "\n",
                "# Get a few test samples\n",
                "test_iter = iter(test_loader)\n",
                "images, labels, metadata = next(test_iter)\n",
                "images_gpu = images.to(device)\n",
                "\n",
                "with torch.no_grad():\n",
                "    predictions = torch.sigmoid(best_model(images_gpu)).cpu().numpy()\n",
                "\n",
                "# Plot first 3\n",
                "for i in range(min(3, len(images))):\n",
                "    img = images[i].numpy()\n",
                "    # Denormalize for visualization\n",
                "    img = img * 6 - 3\n",
                "    img = img * np.array([545, 476, 571, 532, 614, 731, 811, 872, 856, 611]).reshape(-1, 1, 1)\n",
                "    img = img + np.array([1339, 1167, 1002, 1296, 1835, 2149, 2290, 2410, 2004, 1075]).reshape(-1, 1, 1)\n",
                "    \n",
                "    pred = predictions[i, 0]\n",
                "    gt = labels[i, 0].numpy()\n",
                "    \n",
                "    fire = metadata['fire_key'][i]\n",
                "    stage = metadata['stage'][i]\n",
                "    \n",
                "    fig = plot_prediction(\n",
                "        img, pred, gt,\n",
                "        title=f\"{fire} - {stage}\"\n",
                "    )\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Done! üéâ\n",
                "\n",
                "Your trained model is saved at:\n",
                "- `checkpoints/best_model.pth` - Best validation IoU\n",
                "- `checkpoints/final_model.pth` - Final epoch\n",
                "\n",
                "For inference on new images, use:\n",
                "```python\n",
                "from inference.predict import FirePredictor\n",
                "\n",
                "predictor = FirePredictor('checkpoints/best_model.pth')\n",
                "severity, metadata = predictor.predict_file('new_image.tif', 'output.tif')\n",
                "```"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}