{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# \ud83d\udd25 California Fire Model - A100 Optimized Training\n",
                "\n",
                "**High-performance training notebook for Google Colab A100**\n",
                "\n",
                "Optimizations:\n",
                "- \u2705 Batch size 36 (A100 40GB can handle it)\n",
                "- \u2705 BF16 mixed precision (A100 native)\n",
                "- \u2705 8 workers + prefetch for local SSD\n",
                "- \u2705 Gradient accumulation for larger effective batch\n",
                "- \u2705 OneCycleLR for faster convergence\n",
                "- \u2705 Aggressive augmentation\n",
                "- \u2705 Per-fire validation tracking\n",
                "\n",
                "**Prerequisites:** Run `01_colab_setup.ipynb` first!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# CONFIGURATION - A100 OPTIMIZED\n",
                "# ============================================================\n",
                "\n",
                "# Data paths (local SSD - fast!)\n",
                "LOCAL_DATA_PATH = \"/content/local_data\"\n",
                "CODE_PATH = \"/content/California-Fire-Model\"\n",
                "\n",
                "# A100 Optimized settings\n",
                "BATCH_SIZE = 36           # A100 40GB can handle 36 easily\n",
                "NUM_WORKERS = 8           # Local SSD can feed 8 workers\n",
                "PREFETCH_FACTOR = 4       # Prefetch 4 batches per worker\n",
                "\n",
                "# Training\n",
                "EPOCHS = 60               # More epochs for better convergence\n",
                "LEARNING_RATE = 3e-4      # Higher LR with OneCycleLR\n",
                "WEIGHT_DECAY = 1e-4\n",
                "GRADIENT_ACCUMULATION = 2 # Effective batch = 36*2 = 72\n",
                "\n",
                "# Mixed precision (BF16 is optimal for A100)\n",
                "USE_BF16 = True           # Use bfloat16 on A100\n",
                "\n",
                "# Model\n",
                "BASE_CHANNELS = 64        # Standard U-Net width\n",
                "USE_ATTENTION = True\n",
                "DROPOUT = 0.2\n",
                "\n",
                "# Loss weights (tuned for good probability output)\n",
                "BCE_WEIGHT = 0.4\n",
                "DICE_WEIGHT = 0.4\n",
                "FOCAL_WEIGHT = 0.2        # Add focal loss for hard examples\n",
                "POS_WEIGHT = 2.5          # Weight burned pixels more\n",
                "\n",
                "# Checkpointing\n",
                "SAVE_TO_DRIVE = True\n",
                "DRIVE_CHECKPOINT_PATH = \"/content/drive/MyDrive/California_Fire_Model/checkpoints\"\n",
                "\n",
                "print(\"\u2705 Configuration loaded\")\n",
                "print(f\"   Batch size: {BATCH_SIZE} x {GRADIENT_ACCUMULATION} = {BATCH_SIZE * GRADIENT_ACCUMULATION} effective\")\n",
                "print(f\"   Workers: {NUM_WORKERS}\")\n",
                "print(f\"   Mixed precision: {'BF16' if USE_BF16 else 'FP16'}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.insert(0, CODE_PATH)\n",
                "\n",
                "import os\n",
                "import time\n",
                "import json\n",
                "from pathlib import Path\n",
                "from datetime import datetime\n",
                "from collections import defaultdict\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import DataLoader\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from tqdm.auto import tqdm\n",
                "\n",
                "# Check GPU\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"\\n\ud83d\udd27 Device: {device}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
                "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
                "    \n",
                "    # Check for A100 and BF16 support\n",
                "    if torch.cuda.is_bf16_supported():\n",
                "        print(\"   \u2705 BF16 supported\")\n",
                "    else:\n",
                "        USE_BF16 = False\n",
                "        print(\"   \u26a0\ufe0f BF16 not supported, using FP16\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Create Datasets"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import rasterio\n",
                "import albumentations as A\n",
                "from torch.utils.data import Dataset\n",
                "\n",
                "# ============================================================\n",
                "# BAND STATISTICS - Update these after running compute_statistics.py!\n",
                "# ============================================================\n",
                "# Default California stats (update if you computed your own)\n",
                "BAND_MEANS = [1339, 1167, 1002, 1296, 1835, 2149, 2290, 2410, 2004, 1075]\n",
                "BAND_STDS = [545, 476, 571, 532, 614, 731, 811, 872, 856, 611]\n",
                "\n",
                "BAND_MEANS = np.array(BAND_MEANS, dtype=np.float32)\n",
                "BAND_STDS = np.array(BAND_STDS, dtype=np.float32)\n",
                "\n",
                "# Training fires and test fires\n",
                "TRAINING_FIRE_KEYS = ['dixie', 'caldor', 'creek', 'camp', 'mendocino', 'thomas', 'kincade', 'woolsey']\n",
                "TEST_FIRE_KEYS = []  # Using all fires for training\n",
                "\n",
                "print(f\"Training fires: {len(TRAINING_FIRE_KEYS)}\")\n",
                "print(f\"Test fires: {len(TEST_FIRE_KEYS)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class CaliforniaFireDatasetColab(Dataset):\n",
                "    \"\"\"\n",
                "    Optimized dataset for Colab A100 training.\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self, data_dirs, mode='train', augment=True, fire_keys=None):\n",
                "        self.mode = mode\n",
                "        self.augment = augment and (mode == 'train')\n",
                "        \n",
                "        # Collect tiles\n",
                "        self.samples = []\n",
                "        for data_dir in data_dirs:\n",
                "            data_path = Path(data_dir)\n",
                "            if not data_path.exists():\n",
                "                continue\n",
                "                \n",
                "            for tif_file in data_path.rglob(\"*.tif\"):\n",
                "                # Extract fire key from path\n",
                "                rel_path = str(tif_file.relative_to(data_path))\n",
                "                parts = rel_path.split('/')\n",
                "                \n",
                "                if 'fires' in str(tif_file):\n",
                "                    fire_key = parts[0]  # Folder name (caldor, dixie, etc.)\n",
                "                else:\n",
                "                    fire_key = 'healthy'\n",
                "                \n",
                "                # Filter by fire keys if specified\n",
                "                if fire_keys is not None:\n",
                "                    if fire_key not in fire_keys and fire_key != 'healthy':\n",
                "                        continue\n",
                "                \n",
                "                self.samples.append({\n",
                "                    'path': str(tif_file),\n",
                "                    'fire_key': fire_key,\n",
                "                })\n",
                "        \n",
                "        print(f\"   {mode.upper()}: {len(self.samples)} tiles\")\n",
                "        \n",
                "        # Aggressive augmentation for training\n",
                "        if self.augment:\n",
                "            self.transform = A.Compose([\n",
                "                A.RandomRotate90(p=0.5),\n",
                "                A.HorizontalFlip(p=0.5),\n",
                "                A.VerticalFlip(p=0.5),\n",
                "                A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.15, rotate_limit=45, p=0.5),\n",
                "                A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, p=0.4),\n",
                "                A.GaussNoise(std_limit=(5, 25), per_channel=True, p=0.3),\n",
                "                A.CoarseDropout(num_holes_range=(2, 5), hole_height_range=(16, 32), \n",
                "                               hole_width_range=(16, 32), p=0.25),\n",
                "            ])\n",
                "        else:\n",
                "            self.transform = None\n",
                "    \n",
                "    def __len__(self):\n",
                "        return len(self.samples)\n",
                "    \n",
                "    def normalize(self, image):\n",
                "        image = np.clip(image, 0, 10000).astype(np.float32)\n",
                "        for i in range(10):\n",
                "            image[i] = (image[i] - BAND_MEANS[i]) / (BAND_STDS[i] + 1e-6)\n",
                "        image = np.clip(image, -3, 3)\n",
                "        image = (image + 3) / 6\n",
                "        return image\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        sample = self.samples[idx]\n",
                "        \n",
                "        with rasterio.open(sample['path']) as src:\n",
                "            data = src.read()\n",
                "        \n",
                "        # Handle size\n",
                "        _, h, w = data.shape\n",
                "        if h != 256 or w != 256:\n",
                "            padded = np.zeros((data.shape[0], 256, 256), dtype=data.dtype)\n",
                "            padded[:, :min(h,256), :min(w,256)] = data[:, :min(h,256), :min(w,256)]\n",
                "            data = padded\n",
                "        \n",
                "        # Split bands and label\n",
                "        image = data[:10]\n",
                "        label = data[10] if data.shape[0] > 10 else np.zeros((256, 256), dtype=np.float32)\n",
                "        \n",
                "        # Clean NaN\n",
                "        image = np.nan_to_num(image, nan=0.0, posinf=10000.0, neginf=0.0)\n",
                "        label = np.nan_to_num(label, nan=0.0, posinf=1.0, neginf=0.0)\n",
                "        label = np.clip(label, 0.0, 1.0).astype(np.float32)\n",
                "        \n",
                "        # Normalize\n",
                "        image = self.normalize(image)\n",
                "        \n",
                "        # Augment\n",
                "        if self.transform:\n",
                "            image_hwc = image.transpose(1, 2, 0)\n",
                "            augmented = self.transform(image=image_hwc, mask=label)\n",
                "            image = augmented['image'].transpose(2, 0, 1)\n",
                "            label = augmented['mask']\n",
                "        \n",
                "        return (\n",
                "            torch.from_numpy(image).float(),\n",
                "            torch.from_numpy(label).float().unsqueeze(0),\n",
                "            sample['fire_key']\n",
                "        )\n",
                "\n",
                "print(\"\u2705 Dataset class defined\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1.5 Compute Band Statistics (Run Once)\n",
                "\n",
                "Computes actual mean/std from your training data for better normalization."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# COMPUTE BAND STATISTICS FROM TRAINING DATA\n",
                "# ============================================================\n",
                "# Uses efficient streaming algorithm - memory efficient\n",
                "\n",
                "def compute_band_statistics(data_dirs, max_tiles=1000):\n",
                "    \"\"\"\n",
                "    Compute mean and std for each band using streaming algorithm.\n",
                "    Memory efficient - doesn't load all data at once.\n",
                "    \"\"\"\n",
                "    print(\"\ud83d\udcca Computing band statistics from training data...\")\n",
                "    \n",
                "    # Collect tiles\n",
                "    all_tiles = []\n",
                "    for data_dir in data_dirs:\n",
                "        data_path = Path(data_dir)\n",
                "        if data_path.exists():\n",
                "            all_tiles.extend(list(data_path.rglob('*.tif')))\n",
                "    \n",
                "    if len(all_tiles) == 0:\n",
                "        print(\"\u26a0\ufe0f No tiles found! Using default statistics.\")\n",
                "        return None\n",
                "    \n",
                "    print(f\"   Found {len(all_tiles)} tiles\")\n",
                "    \n",
                "    # Sample if too many\n",
                "    if max_tiles and len(all_tiles) > max_tiles:\n",
                "        np.random.seed(42)\n",
                "        all_tiles = list(np.random.choice(all_tiles, max_tiles, replace=False))\n",
                "        print(f\"   Sampling {max_tiles} tiles\")\n",
                "    \n",
                "    NUM_BANDS = 10\n",
                "    \n",
                "    # Batch statistics collection\n",
                "    all_band_means = []\n",
                "    all_band_stds = []\n",
                "    all_band_mins = []\n",
                "    all_band_maxs = []\n",
                "    \n",
                "    valid_tiles = 0\n",
                "    total_pixels = 0\n",
                "    \n",
                "    for tile_path in tqdm(all_tiles, desc=\"Computing stats\"):\n",
                "        try:\n",
                "            with rasterio.open(tile_path) as src:\n",
                "                data = src.read()\n",
                "                \n",
                "                if data.shape[0] < NUM_BANDS:\n",
                "                    continue\n",
                "                \n",
                "                # Extract spectral bands (not label)\n",
                "                spectral = data[:NUM_BANDS].astype(np.float32)\n",
                "                spectral = spectral.reshape(NUM_BANDS, -1)\n",
                "                \n",
                "                # Mask invalid pixels\n",
                "                valid_mask = np.isfinite(spectral).all(axis=0)\n",
                "                valid_mask &= (spectral[0] > 0) & (spectral[0] < 10000)\n",
                "                \n",
                "                spectral = spectral[:, valid_mask]\n",
                "                \n",
                "                if spectral.shape[1] < 100:\n",
                "                    continue\n",
                "                \n",
                "                valid_tiles += 1\n",
                "                total_pixels += spectral.shape[1]\n",
                "                \n",
                "                # Collect per-tile stats\n",
                "                all_band_means.append(spectral.mean(axis=1))\n",
                "                all_band_stds.append(spectral.std(axis=1))\n",
                "                all_band_mins.append(spectral.min(axis=1))\n",
                "                all_band_maxs.append(spectral.max(axis=1))\n",
                "                \n",
                "        except Exception as e:\n",
                "            continue\n",
                "    \n",
                "    if valid_tiles == 0:\n",
                "        print(\"\u26a0\ufe0f No valid tiles! Using default statistics.\")\n",
                "        return None\n",
                "    \n",
                "    # Aggregate statistics\n",
                "    all_band_means = np.array(all_band_means)\n",
                "    all_band_stds = np.array(all_band_stds)\n",
                "    all_band_mins = np.array(all_band_mins)\n",
                "    all_band_maxs = np.array(all_band_maxs)\n",
                "    \n",
                "    stats = {\n",
                "        'means': all_band_means.mean(axis=0).tolist(),\n",
                "        'stds': all_band_stds.mean(axis=0).tolist(),\n",
                "        'mins': all_band_mins.min(axis=0).tolist(),\n",
                "        'maxs': all_band_maxs.max(axis=0).tolist(),\n",
                "        'tile_count': valid_tiles,\n",
                "        'pixel_count': int(total_pixels),\n",
                "    }\n",
                "    \n",
                "    return stats\n",
                "\n",
                "print(\"\u2705 Statistics computation function defined\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run statistics computation\n",
                "data_dirs_for_stats = [\n",
                "    f\"{LOCAL_DATA_PATH}/fires\",\n",
                "    f\"{LOCAL_DATA_PATH}/healthy\",\n",
                "]\n",
                "\n",
                "computed_stats = compute_band_statistics(data_dirs_for_stats, max_tiles=1000)\n",
                "\n",
                "if computed_stats:\n",
                "    # Update the global variables\n",
                "    BAND_MEANS = np.array(computed_stats['means'], dtype=np.float32)\n",
                "    BAND_STDS = np.array(computed_stats['stds'], dtype=np.float32)\n",
                "    \n",
                "    print(\"\\n\" + \"=\"*60)\n",
                "    print(\"\ud83d\udcca COMPUTED BAND STATISTICS\")\n",
                "    print(\"=\"*60)\n",
                "    print(f\"   Tiles processed: {computed_stats['tile_count']}\")\n",
                "    print(f\"   Pixels processed: {computed_stats['pixel_count']:,}\")\n",
                "    \n",
                "    BAND_NAMES = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B11', 'B12']\n",
                "    print(\"\\n   Band Statistics:\")\n",
                "    print(f\"   {'Band':<6} {'Mean':>10} {'Std':>10} {'Min':>10} {'Max':>10}\")\n",
                "    print(\"   \" + \"-\"*46)\n",
                "    \n",
                "    for i, band in enumerate(BAND_NAMES):\n",
                "        print(f\"   {band:<6} {BAND_MEANS[i]:>10.1f} {BAND_STDS[i]:>10.1f} {computed_stats['mins'][i]:>10.1f} {computed_stats['maxs'][i]:>10.1f}\")\n",
                "    \n",
                "    print(\"\\n   \ud83d\udcbe Saving to Drive...\")\n",
                "    \n",
                "    # Save to Drive for reference\n",
                "    stats_path = f\"{DRIVE_CHECKPOINT_PATH}/band_statistics.json\"\n",
                "    os.makedirs(DRIVE_CHECKPOINT_PATH, exist_ok=True)\n",
                "    \n",
                "    with open(stats_path, 'w') as f:\n",
                "        json.dump(computed_stats, f, indent=2)\n",
                "    \n",
                "    print(f\"   \u2705 Saved to: {stats_path}\")\n",
                "    \n",
                "    # Print Python code for future reference\n",
                "    print(\"\\n   \ud83d\udcdd Python code for config:\")\n",
                "    means_str = ', '.join([f\"{v:.0f}\" for v in BAND_MEANS])\n",
                "    stds_str = ', '.join([f\"{v:.0f}\" for v in BAND_STDS])\n",
                "    print(f\"   BAND_MEANS = [{means_str}]\")\n",
                "    print(f\"   BAND_STDS = [{stds_str}]\")\n",
                "    print(\"=\"*60)\n",
                "else:\n",
                "    print(\"\\n\u26a0\ufe0f Using default statistics (update after computing from your data)\")\n",
                "    print(f\"   BAND_MEANS = {BAND_MEANS.tolist()}\")\n",
                "    print(f\"   BAND_STDS = {BAND_STDS.tolist()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create datasets\n",
                "data_dirs = [\n",
                "    f\"{LOCAL_DATA_PATH}/fires\",\n",
                "    f\"{LOCAL_DATA_PATH}/healthy\",\n",
                "]\n",
                "\n",
                "# Split training fires into train/val (1 fire for validation)\n",
                "np.random.seed(42)\n",
                "val_fire = TRAINING_FIRE_KEYS[-1]  # Use last fire for validation\n",
                "train_fires = [f for f in TRAINING_FIRE_KEYS if f != val_fire]\n",
                "\n",
                "print(f\"\\n\ud83d\udcca Data Split:\")\n",
                "print(f\"   Train fires: {train_fires}\")\n",
                "print(f\"   Val fire: {val_fire}\")\n",
                "print(f\"   Test fires: {TEST_FIRE_KEYS}\")\n",
                "\n",
                "print(\"\\n\ud83d\udcc2 Creating datasets...\")\n",
                "train_dataset = CaliforniaFireDatasetColab(data_dirs, mode='train', augment=True, fire_keys=train_fires)\n",
                "val_dataset = CaliforniaFireDatasetColab(data_dirs, mode='val', augment=False, fire_keys=[val_fire])\n",
                "test_dataset = CaliforniaFireDatasetColab(data_dirs, mode='test', augment=False, fire_keys=TEST_FIRE_KEYS)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create dataloaders - A100 optimized\n",
                "train_loader = DataLoader(\n",
                "    train_dataset,\n",
                "    batch_size=BATCH_SIZE,\n",
                "    shuffle=True,\n",
                "    num_workers=NUM_WORKERS,\n",
                "    pin_memory=True,\n",
                "    prefetch_factor=PREFETCH_FACTOR,\n",
                "    persistent_workers=True,\n",
                "    drop_last=True,\n",
                ")\n",
                "\n",
                "val_loader = DataLoader(\n",
                "    val_dataset,\n",
                "    batch_size=BATCH_SIZE,\n",
                "    shuffle=False,\n",
                "    num_workers=NUM_WORKERS,\n",
                "    pin_memory=True,\n",
                "    prefetch_factor=PREFETCH_FACTOR,\n",
                "    persistent_workers=True,\n",
                ")\n",
                "\n",
                "print(f\"\\n\ud83d\udce6 DataLoaders:\")\n",
                "print(f\"   Train: {len(train_loader)} batches ({len(train_dataset)} samples)\")\n",
                "print(f\"   Val: {len(val_loader)} batches ({len(val_dataset)} samples)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Create Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import model components\n",
                "from model.architecture import CaliforniaFireModel\n",
                "from model.losses import CombinedLoss, FocalLoss, DiceLoss\n",
                "\n",
                "# Create model\n",
                "model = CaliforniaFireModel(\n",
                "    input_channels=10,\n",
                "    output_channels=1,\n",
                "    base_channels=BASE_CHANNELS,\n",
                "    use_attention=USE_ATTENTION,\n",
                "    dropout=DROPOUT,\n",
                ").to(device)\n",
                "\n",
                "# Count parameters\n",
                "params = sum(p.numel() for p in model.parameters()) / 1e6\n",
                "print(f\"\\n\ud83e\udde0 Model: {params:.2f}M parameters\")\n",
                "\n",
                "# Enable cudnn benchmarking for A100\n",
                "torch.backends.cudnn.benchmark = True\n",
                "print(\"   \u2705 cuDNN benchmark enabled\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Enhanced loss function for better probability output\n",
                "class EnhancedLoss(nn.Module):\n",
                "    \"\"\"\n",
                "    Combined loss optimized for good probability calibration.\n",
                "    \"\"\"\n",
                "    def __init__(self, bce_w=0.4, dice_w=0.4, focal_w=0.2, pos_weight=2.5):\n",
                "        super().__init__()\n",
                "        self.bce_w = bce_w\n",
                "        self.dice_w = dice_w\n",
                "        self.focal_w = focal_w\n",
                "        self.pos_weight = pos_weight\n",
                "    \n",
                "    def dice_loss(self, logits, targets):\n",
                "        probs = torch.sigmoid(logits)\n",
                "        probs_flat = probs.view(-1)\n",
                "        targets_flat = targets.view(-1)\n",
                "        intersection = (probs_flat * targets_flat).sum()\n",
                "        return 1 - (2 * intersection + 1e-6) / (probs_flat.sum() + targets_flat.sum() + 1e-6)\n",
                "    \n",
                "    def focal_loss(self, logits, targets, alpha=0.25, gamma=2.0):\n",
                "        bce = nn.functional.binary_cross_entropy_with_logits(logits, targets, reduction='none')\n",
                "        pt = torch.exp(-bce)\n",
                "        focal = alpha * (1 - pt) ** gamma * bce\n",
                "        return focal.mean()\n",
                "    \n",
                "    def forward(self, logits, targets):\n",
                "        # BCE with positive weight\n",
                "        weight = torch.ones_like(targets)\n",
                "        weight[targets > 0.5] = self.pos_weight\n",
                "        bce_loss = nn.functional.binary_cross_entropy_with_logits(logits, targets, weight=weight)\n",
                "        \n",
                "        # Dice\n",
                "        dice = self.dice_loss(logits, targets)\n",
                "        \n",
                "        # Focal\n",
                "        focal = self.focal_loss(logits, targets)\n",
                "        \n",
                "        total = self.bce_w * bce_loss + self.dice_w * dice + self.focal_w * focal\n",
                "        \n",
                "        return total, {\n",
                "            'bce': bce_loss.item(),\n",
                "            'dice': dice.item(),\n",
                "            'focal': focal.item(),\n",
                "        }\n",
                "\n",
                "criterion = EnhancedLoss(\n",
                "    bce_w=BCE_WEIGHT,\n",
                "    dice_w=DICE_WEIGHT,\n",
                "    focal_w=FOCAL_WEIGHT,\n",
                "    pos_weight=POS_WEIGHT,\n",
                ")\n",
                "\n",
                "print(f\"\\n\ud83d\udcc9 Loss function:\")\n",
                "print(f\"   BCE weight: {BCE_WEIGHT}, Dice weight: {DICE_WEIGHT}, Focal weight: {FOCAL_WEIGHT}\")\n",
                "print(f\"   Positive class weight: {POS_WEIGHT}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Optimizer\n",
                "optimizer = optim.AdamW(\n",
                "    model.parameters(),\n",
                "    lr=LEARNING_RATE,\n",
                "    weight_decay=WEIGHT_DECAY,\n",
                "    betas=(0.9, 0.999),\n",
                ")\n",
                "\n",
                "# OneCycleLR - faster convergence\n",
                "steps_per_epoch = len(train_loader) // GRADIENT_ACCUMULATION\n",
                "scheduler = optim.lr_scheduler.OneCycleLR(\n",
                "    optimizer,\n",
                "    max_lr=LEARNING_RATE,\n",
                "    epochs=EPOCHS,\n",
                "    steps_per_epoch=steps_per_epoch,\n",
                "    pct_start=0.1,  # Warmup 10% of training\n",
                "    anneal_strategy='cos',\n",
                "    div_factor=25,\n",
                "    final_div_factor=1000,\n",
                ")\n",
                "\n",
                "# Mixed precision scaler\n",
                "scaler = torch.cuda.amp.GradScaler()\n",
                "\n",
                "print(f\"\\n\u2699\ufe0f Optimizer: AdamW (lr={LEARNING_RATE}, wd={WEIGHT_DECAY})\")\n",
                "print(f\"   Scheduler: OneCycleLR\")\n",
                "print(f\"   Gradient accumulation: {GRADIENT_ACCUMULATION} steps\")\n",
                "print(f\"   Mixed precision: {'BF16' if USE_BF16 else 'FP16'}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Training Loop"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_epoch(model, loader, criterion, optimizer, scheduler, scaler, device, accum_steps):\n",
                "    \"\"\"Train for one epoch with gradient accumulation.\"\"\"\n",
                "    model.train()\n",
                "    \n",
                "    total_loss = 0.0\n",
                "    loss_components = defaultdict(float)\n",
                "    num_batches = 0\n",
                "    \n",
                "    optimizer.zero_grad()\n",
                "    \n",
                "    pbar = tqdm(loader, desc=\"Training\", leave=False)\n",
                "    \n",
                "    for batch_idx, (images, labels, fire_keys) in enumerate(pbar):\n",
                "        images = images.to(device, non_blocking=True)\n",
                "        labels = labels.to(device, non_blocking=True)\n",
                "        \n",
                "        # Mixed precision forward\n",
                "        dtype = torch.bfloat16 if USE_BF16 else torch.float16\n",
                "        with torch.amp.autocast('cuda', dtype=dtype):\n",
                "            logits = model(images)\n",
                "            loss, components = criterion(logits, labels)\n",
                "            loss = loss / accum_steps  # Scale for accumulation\n",
                "        \n",
                "        # Backward\n",
                "        scaler.scale(loss).backward()\n",
                "        \n",
                "        # Accumulate gradients\n",
                "        if (batch_idx + 1) % accum_steps == 0:\n",
                "            scaler.unscale_(optimizer)\n",
                "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
                "            scaler.step(optimizer)\n",
                "            scaler.update()\n",
                "            optimizer.zero_grad()\n",
                "            scheduler.step()\n",
                "        \n",
                "        total_loss += loss.item() * accum_steps\n",
                "        for k, v in components.items():\n",
                "            loss_components[k] += v\n",
                "        num_batches += 1\n",
                "        \n",
                "        pbar.set_postfix({'loss': total_loss / num_batches})\n",
                "    \n",
                "    avg_loss = total_loss / num_batches\n",
                "    avg_components = {k: v / num_batches for k, v in loss_components.items()}\n",
                "    \n",
                "    return avg_loss, avg_components\n",
                "\n",
                "@torch.no_grad()\n",
                "def validate(model, loader, criterion, device):\n",
                "    \"\"\"Validate with per-fire tracking.\"\"\"\n",
                "    model.eval()\n",
                "    \n",
                "    total_loss = 0.0\n",
                "    per_fire_metrics = defaultdict(lambda: {'mae': [], 'iou': []})\n",
                "    \n",
                "    for images, labels, fire_keys in tqdm(loader, desc=\"Validating\", leave=False):\n",
                "        images = images.to(device, non_blocking=True)\n",
                "        labels = labels.to(device, non_blocking=True)\n",
                "        \n",
                "        dtype = torch.bfloat16 if USE_BF16 else torch.float16\n",
                "        with torch.amp.autocast('cuda', dtype=dtype):\n",
                "            logits = model(images)\n",
                "            loss, _ = criterion(logits, labels)\n",
                "        \n",
                "        total_loss += loss.item()\n",
                "        \n",
                "        # Per-sample metrics\n",
                "        probs = torch.sigmoid(logits)\n",
                "        \n",
                "        for i in range(images.size(0)):\n",
                "            fire = fire_keys[i]\n",
                "            p = probs[i, 0].float().cpu().numpy()\n",
                "            t = labels[i, 0].float().cpu().numpy()\n",
                "            \n",
                "            # MAE\n",
                "            mae = np.abs(p - t).mean()\n",
                "            per_fire_metrics[fire]['mae'].append(mae)\n",
                "            \n",
                "            # IoU\n",
                "            p_bin = (p > 0.5).astype(float)\n",
                "            t_bin = (t > 0.5).astype(float)\n",
                "            intersection = (p_bin * t_bin).sum()\n",
                "            union = p_bin.sum() + t_bin.sum() - intersection\n",
                "            iou = intersection / (union + 1e-6)\n",
                "            per_fire_metrics[fire]['iou'].append(iou)\n",
                "    \n",
                "    avg_loss = total_loss / len(loader)\n",
                "    \n",
                "    # Aggregate per-fire\n",
                "    fire_summary = {}\n",
                "    all_mae = []\n",
                "    all_iou = []\n",
                "    \n",
                "    for fire, metrics in per_fire_metrics.items():\n",
                "        fire_summary[fire] = {\n",
                "            'mae': np.mean(metrics['mae']),\n",
                "            'iou': np.mean(metrics['iou']),\n",
                "        }\n",
                "        all_mae.extend(metrics['mae'])\n",
                "        all_iou.extend(metrics['iou'])\n",
                "    \n",
                "    return {\n",
                "        'loss': avg_loss,\n",
                "        'mae': np.mean(all_mae),\n",
                "        'iou': np.mean(all_iou),\n",
                "        'per_fire': fire_summary,\n",
                "    }\n",
                "\n",
                "print(\"\u2705 Training functions defined\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create checkpoint directory\n",
                "os.makedirs(DRIVE_CHECKPOINT_PATH, exist_ok=True)\n",
                "local_checkpoint_path = \"/content/checkpoints\"\n",
                "os.makedirs(local_checkpoint_path, exist_ok=True)\n",
                "\n",
                "print(f\"\ud83d\udcbe Checkpoints:\")\n",
                "print(f\"   Local: {local_checkpoint_path}\")\n",
                "print(f\"   Drive: {DRIVE_CHECKPOINT_PATH}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# RESUME FROM CHECKPOINT (Optional)\n",
                "# ============================================================\n",
                "# Set to True to resume from epoch 10 checkpoint\n",
                "\n",
                "RESUME_FROM_CHECKPOINT = True\n",
                "CHECKPOINT_PATH = f\"{DRIVE_CHECKPOINT_PATH}/epoch_10.pth\"\n",
                "START_EPOCH = 10  # Will start from epoch 11\n",
                "\n",
                "# Boost POS_WEIGHT for better fire detection\n",
                "NEW_POS_WEIGHT = 7.0\n",
                "\n",
                "if RESUME_FROM_CHECKPOINT:\n",
                "    print(\"\ud83d\udcc2 Loading checkpoint...\")\n",
                "    \n",
                "    checkpoint = torch.load(CHECKPOINT_PATH)\n",
                "    model.load_state_dict(checkpoint['model_state_dict'])\n",
                "    \n",
                "    print(f\"   \u2705 Loaded model from epoch {checkpoint.get('epoch', 10)}\")\n",
                "    print(f\"   \ud83d\udcc8 Previous best IoU: {checkpoint.get('val_iou', 'N/A')}\")\n",
                "    \n",
                "    # Update criterion with new POS_WEIGHT\n",
                "    criterion.pos_weight = NEW_POS_WEIGHT\n",
                "    print(f\"   \ud83d\udd27 POS_WEIGHT boosted: 2.5 \u2192 {NEW_POS_WEIGHT}\")\n",
                "    \n",
                "    # Note: We create a fresh optimizer/scheduler for the remaining epochs\n",
                "    remaining_epochs = EPOCHS - START_EPOCH\n",
                "    steps_per_epoch = len(train_loader) // GRADIENT_ACCUMULATION\n",
                "    \n",
                "    optimizer = optim.AdamW(\n",
                "        model.parameters(),\n",
                "        lr=LEARNING_RATE * 0.5,  # Lower LR for fine-tuning\n",
                "        weight_decay=WEIGHT_DECAY,\n",
                "    )\n",
                "    \n",
                "    scheduler = optim.lr_scheduler.OneCycleLR(\n",
                "        optimizer,\n",
                "        max_lr=LEARNING_RATE * 0.5,\n",
                "        epochs=remaining_epochs,\n",
                "        steps_per_epoch=steps_per_epoch,\n",
                "        pct_start=0.1,\n",
                "        anneal_strategy='cos',\n",
                "    )\n",
                "    \n",
                "    print(f\"   \u2699\ufe0f New optimizer with LR={LEARNING_RATE * 0.5:.2e}\")\n",
                "    print(f\"   \ufffd\ufffd Will train for {remaining_epochs} more epochs\")\n",
                "else:\n",
                "    START_EPOCH = 0\n",
                "    print(\"Starting fresh training from epoch 0\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# MAIN TRAINING LOOP - ADAPTIVE\n",
                "# ============================================================\n",
                "# Dynamically adjusts POS_WEIGHT if IoU stagnates\n",
                "\n",
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"\ud83d\ude80 STARTING ADAPTIVE A100 TRAINING\")\n",
                "print(\"=\"*70)\n",
                "print(f\"   Epochs: {EPOCHS}\")\n",
                "print(f\"   Batch size: {BATCH_SIZE} x {GRADIENT_ACCUMULATION} = {BATCH_SIZE * GRADIENT_ACCUMULATION}\")\n",
                "print(f\"   Learning rate: {LEARNING_RATE}\")\n",
                "print(f\"   Device: {device}\")\n",
                "print(\"=\"*70 + \"\\n\")\n",
                "\n",
                "# Tracking\n",
                "history = {\n",
                "    'train_loss': [],\n",
                "    'val_loss': [],\n",
                "    'val_mae': [],\n",
                "    'val_iou': [],\n",
                "    'lr': [],\n",
                "    'pos_weight': [],\n",
                "}\n",
                "\n",
                "best_iou = 0.0\n",
                "best_mae = 1.0\n",
                "patience_counter = 0\n",
                "PATIENCE = 15\n",
                "\n",
                "# Adaptive training parameters\n",
                "current_pos_weight = POS_WEIGHT\n",
                "iou_stagnation_counter = 0\n",
                "IOU_STAGNATION_THRESHOLD = 5  # epochs without IoU improvement\n",
                "IOU_MIN_THRESHOLD = 0.05      # if IoU < this after threshold epochs, boost\n",
                "MAX_POS_WEIGHT = 15.0         # maximum pos_weight to try\n",
                "\n",
                "training_start = time.time()\n",
                "\n",
                "for epoch in range(START_EPOCH, EPOCHS):\n",
                "    epoch_start = time.time()\n",
                "    \n",
                "    print(f\"\\n\ud83d\udcc8 Epoch {epoch + 1}/{EPOCHS}\")\n",
                "    print(\"-\" * 50)\n",
                "    \n",
                "    # Train\n",
                "    train_loss, train_components = train_epoch(\n",
                "        model, train_loader, criterion, optimizer, scheduler, scaler, device, GRADIENT_ACCUMULATION\n",
                "    )\n",
                "    \n",
                "    # Validate\n",
                "    val_metrics = validate(model, val_loader, criterion, device)\n",
                "    \n",
                "    current_lr = optimizer.param_groups[0]['lr']\n",
                "    epoch_time = time.time() - epoch_start\n",
                "    \n",
                "    # Log\n",
                "    print(f\"   Train Loss: {train_loss:.4f} (BCE={train_components['bce']:.4f}, Dice={train_components['dice']:.4f})\")\n",
                "    print(f\"   Val Loss: {val_metrics['loss']:.4f}\")\n",
                "    print(f\"   Val MAE: {val_metrics['mae']:.4f}\")\n",
                "    print(f\"   Val IoU: {val_metrics['iou']:.4f}\")\n",
                "    print(f\"   LR: {current_lr:.2e} | POS_WEIGHT: {current_pos_weight:.1f}\")\n",
                "    print(f\"   Time: {epoch_time:.1f}s\")\n",
                "    \n",
                "    # Per-fire metrics\n",
                "    if val_metrics['per_fire']:\n",
                "        print(\"\\n   Per-Fire IoU:\")\n",
                "        for fire, metrics in sorted(val_metrics['per_fire'].items()):\n",
                "            print(f\"      {fire:<25}: {metrics['iou']:.4f} (MAE: {metrics['mae']:.4f})\")\n",
                "    \n",
                "    # History\n",
                "    history['train_loss'].append(train_loss)\n",
                "    history['val_loss'].append(val_metrics['loss'])\n",
                "    history['val_mae'].append(val_metrics['mae'])\n",
                "    history['val_iou'].append(val_metrics['iou'])\n",
                "    history['lr'].append(current_lr)\n",
                "    history['pos_weight'].append(current_pos_weight)\n",
                "    \n",
                "    # ============================================================\n",
                "    # ADAPTIVE POS_WEIGHT ADJUSTMENT\n",
                "    # ============================================================\n",
                "    improved = False\n",
                "    \n",
                "    if val_metrics['iou'] > best_iou * 1.05:  # 5% improvement threshold\n",
                "        best_iou = val_metrics['iou']\n",
                "        improved = True\n",
                "        iou_stagnation_counter = 0\n",
                "        \n",
                "        # Save best (local first, then Drive)\n",
                "        best_path = f\"{local_checkpoint_path}/best_model.pth\"\n",
                "        torch.save({\n",
                "            'epoch': epoch,\n",
                "            'model_state_dict': model.state_dict(),\n",
                "            'optimizer_state_dict': optimizer.state_dict(),\n",
                "            'val_iou': val_metrics['iou'],\n",
                "            'val_mae': val_metrics['mae'],\n",
                "            'pos_weight': current_pos_weight,\n",
                "        }, best_path)\n",
                "        \n",
                "        # Copy to Drive\n",
                "        if SAVE_TO_DRIVE:\n",
                "            import shutil\n",
                "            shutil.copy(best_path, f\"{DRIVE_CHECKPOINT_PATH}/best_model.pth\")\n",
                "        \n",
                "        print(f\"\\n   \u2b50 NEW BEST IoU: {val_metrics['iou']:.4f}\")\n",
                "    else:\n",
                "        iou_stagnation_counter += 1\n",
                "    \n",
                "    if val_metrics['mae'] < best_mae:\n",
                "        best_mae = val_metrics['mae']\n",
                "    \n",
                "    # Check for stagnation and boost POS_WEIGHT\n",
                "    if (iou_stagnation_counter >= IOU_STAGNATION_THRESHOLD and \n",
                "        val_metrics['iou'] < IOU_MIN_THRESHOLD and \n",
                "        current_pos_weight < MAX_POS_WEIGHT):\n",
                "        \n",
                "        old_weight = current_pos_weight\n",
                "        current_pos_weight = min(current_pos_weight * 2, MAX_POS_WEIGHT)\n",
                "        \n",
                "        # Update criterion with new pos_weight\n",
                "        criterion.pos_weight = current_pos_weight\n",
                "        \n",
                "        print(f\"\\n   \ud83d\udd27 ADAPTIVE ADJUSTMENT: POS_WEIGHT {old_weight:.1f} \u2192 {current_pos_weight:.1f}\")\n",
                "        print(f\"      (IoU stagnated at {val_metrics['iou']:.4f} for {iou_stagnation_counter} epochs)\")\n",
                "        \n",
                "        iou_stagnation_counter = 0  # Reset counter\n",
                "    \n",
                "    # Early stopping based on IoU\n",
                "    if improved:\n",
                "        patience_counter = 0\n",
                "    else:\n",
                "        patience_counter += 1\n",
                "        if patience_counter >= PATIENCE:\n",
                "            print(f\"\\n\u26a0\ufe0f Early stopping triggered (no improvement for {PATIENCE} epochs)\")\n",
                "            break\n",
                "    \n",
                "    # Periodic checkpoint\n",
                "    if (epoch + 1) % 10 == 0:\n",
                "        periodic_path = f\"{local_checkpoint_path}/epoch_{epoch+1}.pth\"\n",
                "        torch.save({'epoch': epoch, 'model_state_dict': model.state_dict()}, periodic_path)\n",
                "        \n",
                "        if SAVE_TO_DRIVE:\n",
                "            import shutil\n",
                "            shutil.copy(periodic_path, f\"{DRIVE_CHECKPOINT_PATH}/epoch_{epoch+1}.pth\")\n",
                "        \n",
                "        print(f\"   \ud83d\udcbe Checkpoint saved: epoch_{epoch+1}.pth\")\n",
                "\n",
                "# Final save\n",
                "total_time = time.time() - training_start\n",
                "\n",
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"\ud83c\udf89 TRAINING COMPLETE!\")\n",
                "print(\"=\"*70)\n",
                "print(f\"   Total time: {total_time/3600:.1f} hours\")\n",
                "print(f\"   Best IoU: {best_iou:.4f}\")\n",
                "print(f\"   Best MAE: {best_mae:.4f}\")\n",
                "print(f\"   Final POS_WEIGHT: {current_pos_weight:.1f}\")\n",
                "print(f\"   Checkpoints saved to: {DRIVE_CHECKPOINT_PATH}\")\n",
                "print(\"=\"*70)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Training History"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot training history\n",
                "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
                "\n",
                "# Loss\n",
                "axes[0, 0].plot(history['train_loss'], label='Train', linewidth=2)\n",
                "axes[0, 0].plot(history['val_loss'], label='Val', linewidth=2)\n",
                "axes[0, 0].set_xlabel('Epoch')\n",
                "axes[0, 0].set_ylabel('Loss')\n",
                "axes[0, 0].set_title('Loss', fontsize=12, fontweight='bold')\n",
                "axes[0, 0].legend()\n",
                "axes[0, 0].grid(True, alpha=0.3)\n",
                "\n",
                "# IoU\n",
                "axes[0, 1].plot(history['val_iou'], 'g-', linewidth=2)\n",
                "axes[0, 1].axhline(best_iou, color='r', linestyle='--', label=f'Best: {best_iou:.4f}')\n",
                "axes[0, 1].set_xlabel('Epoch')\n",
                "axes[0, 1].set_ylabel('IoU')\n",
                "axes[0, 1].set_title('Validation IoU', fontsize=12, fontweight='bold')\n",
                "axes[0, 1].legend()\n",
                "axes[0, 1].grid(True, alpha=0.3)\n",
                "\n",
                "# MAE\n",
                "axes[1, 0].plot(history['val_mae'], 'r-', linewidth=2)\n",
                "axes[1, 0].axhline(best_mae, color='g', linestyle='--', label=f'Best: {best_mae:.4f}')\n",
                "axes[1, 0].set_xlabel('Epoch')\n",
                "axes[1, 0].set_ylabel('MAE')\n",
                "axes[1, 0].set_title('Validation MAE', fontsize=12, fontweight='bold')\n",
                "axes[1, 0].legend()\n",
                "axes[1, 0].grid(True, alpha=0.3)\n",
                "\n",
                "# LR\n",
                "axes[1, 1].semilogy(history['lr'], 'purple', linewidth=2)\n",
                "axes[1, 1].set_xlabel('Epoch')\n",
                "axes[1, 1].set_ylabel('Learning Rate')\n",
                "axes[1, 1].set_title('Learning Rate Schedule', fontsize=12, fontweight='bold')\n",
                "axes[1, 1].grid(True, alpha=0.3)\n",
                "\n",
                "plt.suptitle('\ud83d\udd25 California Fire Model - Training History', fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.savefig(f\"{DRIVE_CHECKPOINT_PATH}/training_history.png\", dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "# Save history\n",
                "with open(f\"{DRIVE_CHECKPOINT_PATH}/training_history.json\", 'w') as f:\n",
                "    json.dump(history, f, indent=2)\n",
                "\n",
                "print(f\"\\n\u2705 Training history saved!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Quick Test"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load best model and test\n",
                "model.load_state_dict(torch.load(f\"{local_checkpoint_path}/best_model.pth\")['model_state_dict'])\n",
                "model.eval()\n",
                "\n",
                "# Get a sample\n",
                "sample_batch = next(iter(val_loader))\n",
                "images, labels, fire_keys = sample_batch\n",
                "images = images.to(device)\n",
                "\n",
                "with torch.no_grad():\n",
                "    with torch.cuda.amp.autocast():\n",
                "        logits = model(images)\n",
                "    probs = torch.sigmoid(logits).cpu().numpy()\n",
                "\n",
                "# Visualize\n",
                "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
                "\n",
                "for i in range(4):\n",
                "    pred = probs[i, 0]\n",
                "    gt = labels[i, 0].numpy()\n",
                "    fire = fire_keys[i]\n",
                "    \n",
                "    # Prediction\n",
                "    axes[0, i].imshow(pred, cmap='hot', vmin=0, vmax=1)\n",
                "    axes[0, i].set_title(f\"{fire}\\nPred: {pred.mean():.1%}\")\n",
                "    axes[0, i].axis('off')\n",
                "    \n",
                "    # Ground truth\n",
                "    axes[1, i].imshow(gt, cmap='hot', vmin=0, vmax=1)\n",
                "    axes[1, i].set_title(f\"GT: {gt.mean():.1%}\")\n",
                "    axes[1, i].axis('off')\n",
                "\n",
                "axes[0, 0].set_ylabel('Prediction', fontsize=12)\n",
                "axes[1, 0].set_ylabel('Ground Truth', fontsize=12)\n",
                "\n",
                "plt.suptitle('Sample Predictions', fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(\"\\n\u2705 Model is working!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## \u2705 Training Complete!\n",
                "\n",
                "**Your model is saved at:**\n",
                "- Google Drive: `California_Fire_Model/checkpoints/best_model.pth`\n",
                "\n",
                "**Next steps:**\n",
                "1. Download `best_model.pth` from Drive\n",
                "2. Use it in your hackathon demo with `03_demo.ipynb`\n",
                "\n",
                "**Metrics:**\n",
                "- Best IoU: Check the training output above\n",
                "- Best MAE: Check the training output above"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Comprehensive Model Test\\n",
                "\\n",
                "Test the trained model on 10+ California forest fire images with proper preprocessing."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# COMPREHENSIVE MODEL TEST - 10+ CALIFORNIA FOREST FIRES\n",
                "# ============================================================\n",
                "# Tests model on forest/mountain fire tiles with proper preprocessing\n",
                "\n",
                "import matplotlib.pyplot as plt\n",
                "from collections import defaultdict\n",
                "import pandas as pd\n",
                "\n",
                "# Load best model\n",
                "checkpoint = torch.load(f\"{DRIVE_CHECKPOINT_PATH}/best_model.pth\", weights_only=False)\n",
                "model.load_state_dict(checkpoint['model_state_dict'])\n",
                "model.eval()\n",
                "print(f\"\u2705 Loaded model from epoch {checkpoint.get('epoch', 'unknown')}\")\n",
                "print(f\"   Best val IoU: {checkpoint.get('val_iou', 'N/A')}\")\n",
                "\n",
                "# Forest/mountain fires for testing (similar to training distribution)\n",
                "TEST_FIRES = ['dixie', 'caldor', 'camp', 'creek', 'mendocino', 'thomas']\n",
                "SAMPLES_PER_FIRE = 2  # 2 samples per fire = 12 total\n",
                "MIN_FIRE_PERCENT = 10  # At least 10% fire damage in tile\n",
                "\n",
                "# Collect test samples\n",
                "test_samples = []\n",
                "\n",
                "for fire in TEST_FIRES:\n",
                "    fire_samples = [s for s in train_dataset.samples if s['fire_key'] == fire]\n",
                "    found = 0\n",
                "    \n",
                "    for sample in fire_samples:\n",
                "        if found >= SAMPLES_PER_FIRE:\n",
                "            break\n",
                "            \n",
                "        with rasterio.open(sample['path']) as src:\n",
                "            data = src.read()\n",
                "        \n",
                "        if data.shape[0] < 11:\n",
                "            continue\n",
                "            \n",
                "        label = data[10].astype(np.float32)\n",
                "        label = np.nan_to_num(label, nan=0.0)\n",
                "        fire_percent = (label > 0.5).mean() * 100\n",
                "        \n",
                "        if fire_percent >= MIN_FIRE_PERCENT:\n",
                "            test_samples.append({\n",
                "                'path': sample['path'],\n",
                "                'fire': fire,\n",
                "                'fire_percent': fire_percent,\n",
                "            })\n",
                "            found += 1\n",
                "\n",
                "print(f\"\\n\ud83d\udcca Found {len(test_samples)} test samples with >={MIN_FIRE_PERCENT}% fire damage\")\n",
                "for fire in TEST_FIRES:\n",
                "    count = len([s for s in test_samples if s['fire'] == fire])\n",
                "    print(f\"   {fire}: {count} samples\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# RUN PREDICTIONS AND COMPUTE METRICS\n",
                "# ============================================================\n",
                "\n",
                "results = []\n",
                "\n",
                "for i, sample in enumerate(test_samples):\n",
                "    # Load data\n",
                "    with rasterio.open(sample['path']) as src:\n",
                "        data = src.read()\n",
                "    \n",
                "    image = data[:10].astype(np.float32)\n",
                "    label = data[10].astype(np.float32)\n",
                "    \n",
                "    # Clean NaN\n",
                "    image = np.nan_to_num(image, nan=0.0, posinf=10000.0, neginf=0.0)\n",
                "    label = np.nan_to_num(label, nan=0.0)\n",
                "    label = np.clip(label, 0.0, 1.0)\n",
                "    \n",
                "    # Normalize - EXACT same as training\n",
                "    image = np.clip(image, 0, 10000)\n",
                "    for j in range(10):\n",
                "        image[j] = (image[j] - BAND_MEANS[j]) / (BAND_STDS[j] + 1e-6)\n",
                "    image = np.clip(image, -3, 3)\n",
                "    image = (image + 3) / 6\n",
                "    \n",
                "    # Predict\n",
                "    x = torch.from_numpy(image).unsqueeze(0).float().to(device)\n",
                "    with torch.no_grad():\n",
                "        with torch.amp.autocast('cuda'):\n",
                "            logits = model(x)\n",
                "        probs = torch.sigmoid(logits).float().cpu().numpy()[0, 0]\n",
                "    \n",
                "    # Compute metrics at different thresholds\n",
                "    gt_binary = (label > 0.5).astype(float)\n",
                "    \n",
                "    result = {\n",
                "        'fire': sample['fire'],\n",
                "        'fire_percent': sample['fire_percent'],\n",
                "        'pred_max': probs.max(),\n",
                "        'pred_mean': probs.mean(),\n",
                "        'mae': np.abs(probs - label).mean(),\n",
                "    }\n",
                "    \n",
                "    for thresh in [0.2, 0.3, 0.4, 0.5]:\n",
                "        pred_bin = (probs > thresh).astype(float)\n",
                "        intersection = (pred_bin * gt_binary).sum()\n",
                "        union = pred_bin.sum() + gt_binary.sum() - intersection\n",
                "        iou = intersection / (union + 1e-6)\n",
                "        result[f'iou_{thresh}'] = iou\n",
                "    \n",
                "    result['image'] = image\n",
                "    result['label'] = label\n",
                "    result['probs'] = probs\n",
                "    results.append(result)\n",
                "\n",
                "print(f\"\\n\u2705 Processed {len(results)} samples\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# METRICS SUMMARY TABLE\n",
                "# ============================================================\n",
                "\n",
                "# Create summary dataframe\n",
                "df = pd.DataFrame([{\n",
                "    'Fire': r['fire'],\n",
                "    'Fire %': f\"{r['fire_percent']:.1f}%\",\n",
                "    'Pred Max': f\"{r['pred_max']:.2f}\",\n",
                "    'MAE': f\"{r['mae']:.3f}\",\n",
                "    'IoU@0.2': f\"{r['iou_0.2']:.2f}\",\n",
                "    'IoU@0.3': f\"{r['iou_0.3']:.2f}\",\n",
                "    'IoU@0.4': f\"{r['iou_0.4']:.2f}\",\n",
                "    'IoU@0.5': f\"{r['iou_0.5']:.2f}\",\n",
                "} for r in results])\n",
                "\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"\ud83d\udcca MODEL TEST RESULTS - CALIFORNIA FOREST FIRES\")\n",
                "print(\"=\"*80)\n",
                "print(df.to_string(index=False))\n",
                "\n",
                "# Aggregate stats\n",
                "print(\"\\n\" + \"-\"*80)\n",
                "print(\"\ud83d\udcc8 AGGREGATE METRICS\")\n",
                "print(\"-\"*80)\n",
                "\n",
                "avg_iou_02 = np.mean([r['iou_0.2'] for r in results])\n",
                "avg_iou_03 = np.mean([r['iou_0.3'] for r in results])\n",
                "avg_iou_04 = np.mean([r['iou_0.4'] for r in results])\n",
                "avg_iou_05 = np.mean([r['iou_0.5'] for r in results])\n",
                "avg_mae = np.mean([r['mae'] for r in results])\n",
                "\n",
                "print(f\"   Average MAE:      {avg_mae:.4f}\")\n",
                "print(f\"   Average IoU@0.2:  {avg_iou_02:.4f}\")\n",
                "print(f\"   Average IoU@0.3:  {avg_iou_03:.4f}\")\n",
                "print(f\"   Average IoU@0.4:  {avg_iou_04:.4f}\")\n",
                "print(f\"   Average IoU@0.5:  {avg_iou_05:.4f}\")\n",
                "\n",
                "# Per-fire aggregate\n",
                "print(\"\\n\" + \"-\"*80)\n",
                "print(\"\ud83d\udd25 PER-FIRE AVERAGE IoU@0.3\")\n",
                "print(\"-\"*80)\n",
                "\n",
                "for fire in TEST_FIRES:\n",
                "    fire_results = [r for r in results if r['fire'] == fire]\n",
                "    if fire_results:\n",
                "        avg = np.mean([r['iou_0.3'] for r in fire_results])\n",
                "        print(f\"   {fire:<15}: {avg:.4f}\")\n",
                "\n",
                "print(\"=\"*80)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# VISUALIZATION - 10 SAMPLE PREDICTIONS\n",
                "# ============================================================\n",
                "\n",
                "n_samples = min(10, len(results))\n",
                "fig, axes = plt.subplots(n_samples, 4, figsize=(16, 4*n_samples))\n",
                "\n",
                "for i in range(n_samples):\n",
                "    r = results[i]\n",
                "    \n",
                "    # RGB composite\n",
                "    rgb = np.stack([r['image'][3], r['image'][2], r['image'][1]], axis=0)\n",
                "    rgb = np.clip(rgb, 0, 1).transpose(1, 2, 0)\n",
                "    \n",
                "    # Row 1: RGB\n",
                "    axes[i, 0].imshow(rgb)\n",
                "    axes[i, 0].set_title(f\"{r['fire']}\\nRGB\", fontsize=10)\n",
                "    axes[i, 0].axis('off')\n",
                "    \n",
                "    # Row 2: Ground Truth\n",
                "    axes[i, 1].imshow(r['label'], cmap='hot', vmin=0, vmax=1)\n",
                "    axes[i, 1].set_title(f\"Ground Truth\\n{r['fire_percent']:.1f}% fire\", fontsize=10)\n",
                "    axes[i, 1].axis('off')\n",
                "    \n",
                "    # Row 3: Prediction Heatmap\n",
                "    axes[i, 2].imshow(r['probs'], cmap='hot', vmin=0, vmax=1)\n",
                "    axes[i, 2].set_title(f\"Prediction\\nmax={r['pred_max']:.2f}\", fontsize=10)\n",
                "    axes[i, 2].axis('off')\n",
                "    \n",
                "    # Row 4: Binary @ 0.3\n",
                "    pred_binary = (r['probs'] > 0.3).astype(float)\n",
                "    axes[i, 3].imshow(pred_binary, cmap='hot', vmin=0, vmax=1)\n",
                "    axes[i, 3].set_title(f\"Binary @ 0.3\\nIoU={r['iou_0.3']:.2f}\", fontsize=10)\n",
                "    axes[i, 3].axis('off')\n",
                "\n",
                "plt.suptitle('\ud83d\udd25 California Fire Model - Test Results', fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.savefig(f\"{DRIVE_CHECKPOINT_PATH}/comprehensive_test_results.png\", dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print(f\"\\n\u2705 Results saved to {DRIVE_CHECKPOINT_PATH}/comprehensive_test_results.png\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Test on Random Forest/Deforestation Areas (Earth Engine)\n",
                "\n",
                "Download 10 random forest deforestation areas from Google Earth Engine and test the model.\n",
                "\n",
                "**Note:** The model was trained on FIRE damage. Performance on deforestation is unknown - \n",
                "it may generalize if spectral signatures are similar."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# DOWNLOAD RANDOM FOREST/DEFORESTATION IMAGES FROM GEE\n",
                "# ============================================================\n",
                "# Uses same bands and preprocessing as training data\n",
                "\n",
                "import ee\n",
                "import requests\n",
                "from io import BytesIO\n",
                "\n",
                "# Initialize Earth Engine (should already be authenticated from setup)\n",
                "try:\n",
                "    ee.Initialize()\n",
                "    print(\"\u2705 Earth Engine initialized\")\n",
                "except:\n",
                "    ee.Authenticate()\n",
                "    ee.Initialize()\n",
                "    print(\"\u2705 Earth Engine authenticated and initialized\")\n",
                "\n",
                "# Sentinel-2 bands (same as training)\n",
                "S2_BANDS = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B11', 'B12']\n",
                "\n",
                "# Random forest/deforestation locations (global hotspots)\n",
                "# Mix of deforestation, logging, and intact forest for comparison\n",
                "TEST_LOCATIONS = [\n",
                "    # Amazon deforestation hotspots\n",
                "    {'name': 'amazon_rondonia_1', 'lon': -63.5, 'lat': -10.5, 'year': 2023},\n",
                "    {'name': 'amazon_para_1', 'lon': -55.0, 'lat': -6.0, 'year': 2023},\n",
                "    {'name': 'amazon_mato_grosso', 'lon': -56.5, 'lat': -12.0, 'year': 2023},\n",
                "    \n",
                "    # Southeast Asia deforestation\n",
                "    {'name': 'borneo_kalimantan', 'lon': 116.0, 'lat': 0.5, 'year': 2023},\n",
                "    {'name': 'sumatra_riau', 'lon': 102.0, 'lat': 0.5, 'year': 2023},\n",
                "    \n",
                "    # California forests (for comparison - should detect if degraded)\n",
                "    {'name': 'california_sierra_1', 'lon': -120.5, 'lat': 38.5, 'year': 2023},\n",
                "    {'name': 'california_plumas', 'lon': -121.0, 'lat': 40.0, 'year': 2023},\n",
                "    \n",
                "    # African deforestation\n",
                "    {'name': 'congo_basin', 'lon': 21.0, 'lat': 1.0, 'year': 2023},\n",
                "    \n",
                "    # More California/Oregon forests\n",
                "    {'name': 'oregon_cascade', 'lon': -122.0, 'lat': 44.0, 'year': 2023},\n",
                "    {'name': 'california_shasta', 'lon': -122.5, 'lat': 41.0, 'year': 2023},\n",
                "]\n",
                "\n",
                "print(f\"\ud83d\udccd Will download {len(TEST_LOCATIONS)} test locations\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# DOWNLOAD FUNCTION - Same preprocessing as training data\n",
                "# ============================================================\n",
                "\n",
                "def download_gee_tile(location, tile_size=256):\n",
                "    \"\"\"\n",
                "    Download a tile from GEE with same processing as training data.\n",
                "    \"\"\"\n",
                "    lon, lat = location['lon'], location['lat']\n",
                "    year = location['year']\n",
                "    \n",
                "    # Create point and buffer for tile\n",
                "    point = ee.Geometry.Point([lon, lat])\n",
                "    \n",
                "    # Get Sentinel-2 imagery\n",
                "    # Use cloud-free composite for the year\n",
                "    s2 = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n",
                "        .filterBounds(point) \\\n",
                "        .filterDate(f'{year}-01-01', f'{year}-12-31') \\\n",
                "        .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20)) \\\n",
                "        .select(S2_BANDS) \\\n",
                "        .median()\n",
                "    \n",
                "    # Get 256x256 tile (10m resolution = 2560m x 2560m)\n",
                "    scale = 10  # 10m per pixel\n",
                "    region = point.buffer(tile_size * scale / 2).bounds()\n",
                "    \n",
                "    try:\n",
                "        # Get URL for the image\n",
                "        url = s2.getDownloadURL({\n",
                "            'bands': S2_BANDS,\n",
                "            'region': region,\n",
                "            'scale': scale,\n",
                "            'format': 'NPY',\n",
                "        })\n",
                "        \n",
                "        # Download\n",
                "        response = requests.get(url, timeout=60)\n",
                "        if response.status_code == 200:\n",
                "            data = np.load(BytesIO(response.content), allow_pickle=True)\n",
                "            \n",
                "            # Convert structured array to regular array\n",
                "            if data.dtype.names:\n",
                "                # Structured array - extract bands\n",
                "                bands = [data[band] for band in S2_BANDS]\n",
                "                data = np.stack(bands, axis=0)\n",
                "            \n",
                "            return data\n",
                "        else:\n",
                "            print(f\"   \u274c Download failed: {response.status_code}\")\n",
                "            return None\n",
                "            \n",
                "    except Exception as e:\n",
                "        print(f\"   \u274c Error: {str(e)[:50]}\")\n",
                "        return None\n",
                "\n",
                "print(\"\u2705 Download function defined\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# DOWNLOAD ALL TEST TILES\n",
                "# ============================================================\n",
                "\n",
                "gee_test_results = []\n",
                "\n",
                "print(\"\ud83d\udce5 Downloading test tiles from Earth Engine...\")\n",
                "print(\"-\" * 50)\n",
                "\n",
                "for loc in TEST_LOCATIONS:\n",
                "    print(f\"   Downloading {loc['name']}...\", end=\" \")\n",
                "    \n",
                "    data = download_gee_tile(loc)\n",
                "    \n",
                "    if data is not None:\n",
                "        # Preprocess EXACTLY like training data\n",
                "        image = data.astype(np.float32)\n",
                "        \n",
                "        # Handle shape\n",
                "        if len(image.shape) == 2:\n",
                "            print(f\"\u274c Wrong shape {image.shape}\")\n",
                "            continue\n",
                "        \n",
                "        # Ensure 10 bands\n",
                "        if image.shape[0] != 10:\n",
                "            print(f\"\u274c Wrong bands {image.shape[0]}\")\n",
                "            continue\n",
                "        \n",
                "        # Resize to 256x256 if needed\n",
                "        h, w = image.shape[1], image.shape[2]\n",
                "        if h != 256 or w != 256:\n",
                "            # Center crop or pad\n",
                "            new_image = np.zeros((10, 256, 256), dtype=np.float32)\n",
                "            sh, sw = min(h, 256), min(w, 256)\n",
                "            oh, ow = (h - sh) // 2, (w - sw) // 2\n",
                "            nh, nw = (256 - sh) // 2, (256 - sw) // 2\n",
                "            new_image[:, nh:nh+sh, nw:nw+sw] = image[:, oh:oh+sh, ow:ow+sw]\n",
                "            image = new_image\n",
                "        \n",
                "        # Clean NaN\n",
                "        image = np.nan_to_num(image, nan=0.0, posinf=10000.0, neginf=0.0)\n",
                "        \n",
                "        # Normalize - EXACT same as training\n",
                "        image = np.clip(image, 0, 10000)\n",
                "        for j in range(10):\n",
                "            image[j] = (image[j] - BAND_MEANS[j]) / (BAND_STDS[j] + 1e-6)\n",
                "        image = np.clip(image, -3, 3)\n",
                "        image = (image + 3) / 6\n",
                "        \n",
                "        gee_test_results.append({\n",
                "            'name': loc['name'],\n",
                "            'image': image,\n",
                "            'lon': loc['lon'],\n",
                "            'lat': loc['lat'],\n",
                "        })\n",
                "        print(f\"\u2705 Shape: {image.shape}\")\n",
                "    else:\n",
                "        print(\"\u274c Failed\")\n",
                "\n",
                "print(\"-\" * 50)\n",
                "print(f\"\\n\u2705 Downloaded {len(gee_test_results)} tiles successfully\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# RUN PREDICTIONS ON GEE TILES\n",
                "# ============================================================\n",
                "\n",
                "print(\"\ud83d\udd2e Running predictions on downloaded tiles...\")\n",
                "\n",
                "for result in gee_test_results:\n",
                "    image = result['image']\n",
                "    \n",
                "    # Predict\n",
                "    x = torch.from_numpy(image).unsqueeze(0).float().to(device)\n",
                "    with torch.no_grad():\n",
                "        with torch.amp.autocast('cuda'):\n",
                "            logits = model(x)\n",
                "        probs = torch.sigmoid(logits).float().cpu().numpy()[0, 0]\n",
                "    \n",
                "    result['probs'] = probs\n",
                "    result['pred_max'] = probs.max()\n",
                "    result['pred_mean'] = probs.mean()\n",
                "    result['degradation_percent'] = (probs > 0.3).mean() * 100\n",
                "\n",
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"\ud83d\udcca DEFORESTATION/DEGRADATION PREDICTIONS\")\n",
                "print(\"=\"*70)\n",
                "print(f\"{'Location':<25} {'Max Prob':>10} {'Mean Prob':>10} {'Degradation %':>15}\")\n",
                "print(\"-\"*70)\n",
                "\n",
                "for r in gee_test_results:\n",
                "    print(f\"{r['name']:<25} {r['pred_max']:>10.2f} {r['pred_mean']:>10.4f} {r['degradation_percent']:>14.1f}%\")\n",
                "\n",
                "print(\"=\"*70)\n",
                "print(\"\\n\ud83d\udca1 Note: High degradation % may indicate fire damage, deforestation, or\")\n",
                "print(\"   other vegetation stress the model learned to detect.\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# VISUALIZE GEE PREDICTIONS\n",
                "# ============================================================\n",
                "\n",
                "n_gee = min(10, len(gee_test_results))\n",
                "fig, axes = plt.subplots(n_gee, 3, figsize=(12, 4*n_gee))\n",
                "\n",
                "for i in range(n_gee):\n",
                "    r = gee_test_results[i]\n",
                "    \n",
                "    # RGB composite\n",
                "    rgb = np.stack([r['image'][3], r['image'][2], r['image'][1]], axis=0)\n",
                "    rgb = np.clip(rgb, 0, 1).transpose(1, 2, 0)\n",
                "    \n",
                "    # RGB\n",
                "    axes[i, 0].imshow(rgb)\n",
                "    axes[i, 0].set_title(f\"{r['name']}\\n({r['lat']:.1f}, {r['lon']:.1f})\", fontsize=10)\n",
                "    axes[i, 0].axis('off')\n",
                "    \n",
                "    # Prediction heatmap\n",
                "    axes[i, 1].imshow(r['probs'], cmap='hot', vmin=0, vmax=1)\n",
                "    axes[i, 1].set_title(f\"Degradation Probability\\nmax={r['pred_max']:.2f}\", fontsize=10)\n",
                "    axes[i, 1].axis('off')\n",
                "    \n",
                "    # Binary @ 0.3\n",
                "    axes[i, 2].imshow(r['probs'] > 0.3, cmap='hot')\n",
                "    axes[i, 2].set_title(f\"Binary @ 0.3\\n{r['degradation_percent']:.1f}% detected\", fontsize=10)\n",
                "    axes[i, 2].axis('off')\n",
                "\n",
                "plt.suptitle('\ud83c\udf32 Forest Degradation Detection - GEE Test Images', fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.savefig(f\"{DRIVE_CHECKPOINT_PATH}/gee_deforestation_test.png\", dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print(f\"\\n\u2705 Results saved to {DRIVE_CHECKPOINT_PATH}/gee_deforestation_test.png\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Test on California Vegetation & Fire Areas (NEW)\n",
                "\n",
                "Download 10 random California locations - mix of fire-affected and healthy vegetation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# CALIFORNIA-SPECIFIC TEST LOCATIONS\n",
                "# ============================================================\n",
                "# Recent fire areas + healthy vegetation\n",
                "\n",
                "# California fire locations (2020-2023 major fires)\n",
                "CA_TEST_LOCATIONS = [\n",
                "    # 2021 Dixie Fire area (largest in CA history)\n",
                "    {'name': 'dixie_fire_2023_center', 'lon': -121.4, 'lat': 40.1, 'expected': 'fire'},\n",
                "    {'name': 'dixie_fire_2023_edge', 'lon': -121.2, 'lat': 39.9, 'expected': 'fire'},\n",
                "    \n",
                "    # 2020 Creek Fire\n",
                "    {'name': 'creek_fire_2023', 'lon': -119.3, 'lat': 37.2, 'expected': 'fire'},\n",
                "    \n",
                "    # 2021 Caldor Fire\n",
                "    {'name': 'caldor_fire_2023', 'lon': -120.3, 'lat': 38.7, 'expected': 'fire'},\n",
                "    \n",
                "    # 2020 August Complex Fire\n",
                "    {'name': 'august_complex_2023', 'lon': -122.7, 'lat': 39.8, 'expected': 'fire'},\n",
                "    \n",
                "    # Healthy California forests (should NOT detect fire)\n",
                "    {'name': 'yosemite_healthy', 'lon': -119.6, 'lat': 37.8, 'expected': 'healthy'},\n",
                "    {'name': 'redwood_coast', 'lon': -123.9, 'lat': 41.2, 'expected': 'healthy'},\n",
                "    {'name': 'big_sur_forest', 'lon': -121.8, 'lat': 36.2, 'expected': 'healthy'},\n",
                "    {'name': 'tahoe_forest', 'lon': -120.1, 'lat': 39.1, 'expected': 'healthy'},\n",
                "    {'name': 'sequoia_healthy', 'lon': -118.6, 'lat': 36.5, 'expected': 'healthy'},\n",
                "]\n",
                "\n",
                "print(f\"\ud83d\udccd California Test Locations: {len(CA_TEST_LOCATIONS)}\")\n",
                "print(f\"   Fire areas: {len([l for l in CA_TEST_LOCATIONS if l['expected'] == 'fire'])}\")\n",
                "print(f\"   Healthy vegetation: {len([l for l in CA_TEST_LOCATIONS if l['expected'] == 'healthy'])}\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# DOWNLOAD CALIFORNIA TEST TILES\n",
                "# ============================================================\n",
                "\n",
                "ca_test_results = []\n",
                "\n",
                "print(\"\ud83d\udce5 Downloading California test tiles...\")\n",
                "print(\"-\" * 60)\n",
                "\n",
                "for loc in CA_TEST_LOCATIONS:\n",
                "    print(f\"   {loc['name']} ({loc['expected']})...\", end=\" \")\n",
                "    \n",
                "    # Use 2023 imagery to capture current state\n",
                "    loc_with_year = {**loc, 'year': 2023}\n",
                "    data = download_gee_tile(loc_with_year)\n",
                "    \n",
                "    if data is not None:\n",
                "        # Preprocess EXACTLY like training data\n",
                "        image = data.astype(np.float32)\n",
                "        \n",
                "        if len(image.shape) == 2 or image.shape[0] != 10:\n",
                "            print(f\"\u274c Wrong shape\")\n",
                "            continue\n",
                "        \n",
                "        # Resize if needed\n",
                "        h, w = image.shape[1], image.shape[2]\n",
                "        if h != 256 or w != 256:\n",
                "            new_image = np.zeros((10, 256, 256), dtype=np.float32)\n",
                "            sh, sw = min(h, 256), min(w, 256)\n",
                "            oh, ow = (h - sh) // 2, (w - sw) // 2\n",
                "            nh, nw = (256 - sh) // 2, (256 - sw) // 2\n",
                "            new_image[:, nh:nh+sh, nw:nw+sw] = image[:, oh:oh+sh, ow:ow+sw]\n",
                "            image = new_image\n",
                "        \n",
                "        # Normalize\n",
                "        image = np.nan_to_num(image, nan=0.0, posinf=10000.0, neginf=0.0)\n",
                "        image = np.clip(image, 0, 10000)\n",
                "        for j in range(10):\n",
                "            image[j] = (image[j] - BAND_MEANS[j]) / (BAND_STDS[j] + 1e-6)\n",
                "        image = np.clip(image, -3, 3)\n",
                "        image = (image + 3) / 6\n",
                "        \n",
                "        ca_test_results.append({\n",
                "            'name': loc['name'],\n",
                "            'expected': loc['expected'],\n",
                "            'image': image,\n",
                "            'lon': loc['lon'],\n",
                "            'lat': loc['lat'],\n",
                "        })\n",
                "        print(f\"\u2705\")\n",
                "    else:\n",
                "        print(f\"\u274c\")\n",
                "\n",
                "print(\"-\" * 60)\n",
                "print(f\"\u2705 Downloaded {len(ca_test_results)} California tiles\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# PREDICT & EVALUATE CALIFORNIA TILES\n",
                "# ============================================================\n",
                "\n",
                "print(\"\ud83d\udd2e Running predictions...\")\n",
                "\n",
                "for r in ca_test_results:\n",
                "    x = torch.from_numpy(r['image']).unsqueeze(0).float().to(device)\n",
                "    with torch.no_grad():\n",
                "        with torch.amp.autocast('cuda'):\n",
                "            logits = model(x)\n",
                "        probs = torch.sigmoid(logits).float().cpu().numpy()[0, 0]\n",
                "    \n",
                "    r['probs'] = probs\n",
                "    r['pred_max'] = probs.max()\n",
                "    r['pred_mean'] = probs.mean()\n",
                "    r['fire_percent'] = (probs > 0.3).mean() * 100\n",
                "    \n",
                "    # Evaluate correctness\n",
                "    if r['expected'] == 'fire':\n",
                "        r['correct'] = r['fire_percent'] > 5  # Should detect some fire\n",
                "    else:\n",
                "        r['correct'] = r['fire_percent'] < 10  # Should NOT detect fire\n",
                "\n",
                "# Results table\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"\ud83d\udcca CALIFORNIA FIRE DETECTION TEST\")\n",
                "print(\"=\"*80)\n",
                "print(f\"{'Location':<25} {'Expected':>10} {'Max':>8} {'Fire%':>8} {'Result':>10}\")\n",
                "print(\"-\"*80)\n",
                "\n",
                "for r in ca_test_results:\n",
                "    result_icon = '\u2705' if r['correct'] else '\u274c'\n",
                "    print(f\"{r['name']:<25} {r['expected']:>10} {r['pred_max']:>8.2f} {r['fire_percent']:>7.1f}% {result_icon:>10}\")\n",
                "\n",
                "# Summary\n",
                "correct = sum(1 for r in ca_test_results if r['correct'])\n",
                "total = len(ca_test_results)\n",
                "accuracy = correct / total * 100 if total > 0 else 0\n",
                "\n",
                "print(\"=\"*80)\n",
                "print(f\"\\n\ud83d\udcc8 ACCURACY: {correct}/{total} = {accuracy:.0f}%\")\n",
                "\n",
                "# Breakdown\n",
                "fire_locs = [r for r in ca_test_results if r['expected'] == 'fire']\n",
                "healthy_locs = [r for r in ca_test_results if r['expected'] == 'healthy']\n",
                "\n",
                "fire_correct = sum(1 for r in fire_locs if r['correct'])\n",
                "healthy_correct = sum(1 for r in healthy_locs if r['correct'])\n",
                "\n",
                "print(f\"   Fire detection: {fire_correct}/{len(fire_locs)}\")\n",
                "print(f\"   Healthy (no false positives): {healthy_correct}/{len(healthy_locs)}\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# VISUALIZE CALIFORNIA RESULTS\n",
                "# ============================================================\n",
                "\n",
                "n = len(ca_test_results)\n",
                "fig, axes = plt.subplots(n, 3, figsize=(12, 4*n))\n",
                "\n",
                "for i, r in enumerate(ca_test_results):\n",
                "    # RGB\n",
                "    rgb = np.stack([r['image'][3], r['image'][2], r['image'][1]], axis=0)\n",
                "    rgb = np.clip(rgb, 0, 1).transpose(1, 2, 0)\n",
                "    \n",
                "    result_icon = '\u2705' if r['correct'] else '\u274c'\n",
                "    \n",
                "    axes[i, 0].imshow(rgb)\n",
                "    axes[i, 0].set_title(f\"{r['name']}\\n({r['expected']}) {result_icon}\", fontsize=10)\n",
                "    axes[i, 0].axis('off')\n",
                "    \n",
                "    axes[i, 1].imshow(r['probs'], cmap='hot', vmin=0, vmax=1)\n",
                "    axes[i, 1].set_title(f\"Prediction\\nmax={r['pred_max']:.2f}\", fontsize=10)\n",
                "    axes[i, 1].axis('off')\n",
                "    \n",
                "    axes[i, 2].imshow(r['probs'] > 0.3, cmap='hot')\n",
                "    axes[i, 2].set_title(f\"Binary @ 0.3\\n{r['fire_percent']:.1f}% fire\", fontsize=10)\n",
                "    axes[i, 2].axis('off')\n",
                "\n",
                "plt.suptitle('\ud83d\udd25 California Fire Detection - Real-World Test', fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.savefig(f\"{DRIVE_CHECKPOINT_PATH}/california_test_results.png\", dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print(f\"\\n\u2705 Saved to {DRIVE_CHECKPOINT_PATH}/california_test_results.png\")\n"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "gpuClass": "premium",
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}